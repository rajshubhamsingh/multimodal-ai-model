## Multimodal AI Captioning Pipeline
From Demo to Scalable System â€” Generate and rank image captions using BLIP & CLIP, ready for production.

## ğŸ“Œ Overview
This project implements a scalable multimodal AI pipeline for image caption generation and ranking.
It started as a Colab prototype and has been refactored into modular Python scripts with a configuration file, batch processing, and exportable evaluation reports.

The pipeline can:

Generate multiple candidate captions for each image using BLIP

Rank captions using CLIP

Export results to CSV for human-in-the-loop evaluation

Apply decision rules for auto-publish / review / flag

Scale to large datasets with FAISS-based retrieval

## âœ¨ Features
Modular design â€” reusable Python modules (caption_generator.py, caption_ranker.py, etc.)

Configurable â€” set parameters in config.yaml

Batch processing â€” handle 10x or 100x more images

Human evaluation export â€” outputs/human_eval.csv

Scalable search â€” FAISS for fast similarity queries

## Deployment-ready â€” can be wrapped into FastAPI / Streamlit

Automatable â€” run weekly via cron, GitHub Actions, or Airflow

## ğŸ“‚ Project Structure
bash
Copy
Edit
.
â”œâ”€â”€ config.yaml                # Pipeline configuration
â”œâ”€â”€ run_pipeline.py            # Entry point for batch runs
â”œâ”€â”€ image_loader.py            # Image loading (local & URL)
â”œâ”€â”€ caption_generator.py       # BLIP-based caption generation
â”œâ”€â”€ caption_ranker.py          # CLIP-based caption ranking
â”œâ”€â”€ evaluation.py              # CSV export for human eval
â”œâ”€â”€ utils.py                   # Common utilities
â”œâ”€â”€ images/                    # Input images
â”œâ”€â”€ outputs/                   # Generated captions & CSVs
â””â”€â”€ requirements.txt           # Dependencies

## ğŸš€ Quick Start
1ï¸âƒ£ Install dependencies
bash
Copy
Edit
pip install -r requirements.txt
2ï¸âƒ£ Add images
Place your .jpg, .png, .jpeg, or .webp files in the images/ directory.

3ï¸âƒ£ Run the pipeline
bash
Copy
Edit
python run_pipeline.py
4ï¸âƒ£ Check the results
Captions and rankings will be saved to:

bash
Copy
Edit
outputs/human_eval.csv
âš™ Configuration
Modify config.yaml to set:

Model names (BLIP / CLIP variants)

Input image directory

Output CSV location

Number of captions to generate (generate_n)

Top-K captions to keep (top_k)

Example:

yaml
Copy
Edit
pipeline:
  generate_n: 5
  top_k: 5
ğŸ“Š Turning Data into Action
This pipeline is built for decision-making, not just demos.
Example usage:

Auto-publish captions when score â‰¥ 0.7

Route to review if score between 0.5â€“0.7

Flag for manual writing if score < 0.5 or contains sensitive terms

You can integrate these rules in run_pipeline.py.

## ğŸ“ˆ Scaling Up
Batch size control in config.yaml

FAISS indexing for millions of captions

Schedule weekly runs with cron jobs, GitHub Actions, or Airflow

## ğŸ–¥ Deployment
Possible deployment options:

FastAPI REST API for on-demand captioning

Streamlit / Gradio app for interactive demos

Hugging Face Spaces for public sharing

Docker container for cloud deployment

## ğŸ¤ Contributing
Contributions are welcome!
Please:

Fork the repo

Create a feature branch

Submit a pull request

ğŸ“¬ Contact
Shubham Kumar Singh
ğŸ“§ Email: sk7892990@gmail.com
ğŸ’¼ LinkedIn: https://www.linkedin.com/in/shubham-kumar-singh-001651271/

ğŸ™ GitHub: https://github.com/rajshubhamsingh
    
